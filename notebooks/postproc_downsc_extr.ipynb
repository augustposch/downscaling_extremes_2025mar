{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99f04312-8eed-4353-9ec5-90b253fe982e",
   "metadata": {},
   "source": [
    "## Read in LOCA projections, filter to gridcells and time period, and obtain extreme values\n",
    "\n",
    "August Posch --- February-March 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4ab6b0-f83a-445d-8af9-9ba442bebcfe",
   "metadata": {},
   "source": [
    "This notebook takes in downscaled gridded projections and a set of gridcells of interest, and returns extreme levels for two time periods of interest: midcentury (2031-2050) and end of century (2081-2100). Along the way it also saves the predicted daily precipitation time series and the associated annual precipitation max time series.\n",
    "\n",
    "All necessary parameters are specified in the first code block, as a dictionary called `parameters`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba554caa-059d-48ff-97b6-bb8a6e3c3253",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'path_loca_2044': '../data/LOCA_downscaled/pr.CESM2-LENS.ssp370.r1i1p1f1.2015-2044.LOCA_16thdeg_v20240915.n_east.nc',\n",
    "    'path_loca_2074': '../data/LOCA_downscaled/pr.CESM2-LENS.ssp370.r1i1p1f1.2045-2074.LOCA_16thdeg_v20240915.n_east.nc',\n",
    "    'path_loca_2100': '../data/LOCA_downscaled/pr.CESM2-LENS.ssp370.r1i1p1f1.2075-2100.LOCA_16thdeg_v20240915.n_east.nc',\n",
    "    'path_for_loading_gridcells_npy': '../data/auxil/loca_cells_of_interest_boston.npy',\n",
    "    'save_daily_timeseries': True,\n",
    "    'path_for_saving_daily': '../data/auxil/loca_daily_gba.csv',\n",
    "    'save_annual_max_timeseries': True,\n",
    "    'path_for_saving_annual_max': '../data/auxil/loca_annual_max_gba.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527172b4-7659-4794-9ad5-ef9812e7107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import genextreme as gev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da8e708-0162-4404-b885-27bae0bb462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = xr.open_dataset(parameters['path_loca_2044'], engine='netcdf4')\n",
    "ds2 = xr.open_dataset(parameters['path_loca_2074'], engine='netcdf4')\n",
    "ds3 = xr.open_dataset(parameters['path_loca_2100'], engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddd68f35-2852-47cb-a4b2-0e6d324048d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.concat([ds1, ds2, ds3], 'time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba3cd04-6d56-4c0d-804d-3411f4c43d3e",
   "metadata": {},
   "source": [
    "Steps:\n",
    "1. Slice down to only the Boston gridcells as our restricted domain\n",
    "2. Get annual max precip over that restricted domain (end up with time series, one number per year)\n",
    "3. Use scipy GEV function to calculate 1-100 year value and 1-25 year value\n",
    "4. Send those to Jack for flood modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2da0e0-088a-4c4d-bca6-7a3494fcf4f2",
   "metadata": {},
   "source": [
    "Now load in those gridcells of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a80a61b-ab84-45ef-b42b-7d70ebbf2c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = np.load(parameters['path_for_loading_gridcells_npy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6de0a-d53c-4677-9485-f076ef74188e",
   "metadata": {},
   "source": [
    "## New March 12 - slice down to these gridcells in xarray.\n",
    "\n",
    "Steps:\n",
    "1. Create a new dataset with the coordinates of the old one. It should only have lat and lon dimensions. Call it `mask` and set every value to False.\n",
    "2. Loop through my cells of interest, setting the value to True. Now `mask` is the proper mask.\n",
    "3. convert ds to pandas dataframe only wherever `mask==True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ada59ffb-3f29-4ba6-b09b-7fede973fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_latlons = ds.isel(time=0).drop('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a237f4c-08a5-47a8-8050-2a07b026509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = xr.full_like(only_latlons, False, dtype='bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a68379d-a119-4ffd-a926-66d06d1a4071",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in cells:\n",
    "    lon = cell[0]\n",
    "    lat = cell[1]\n",
    "    mask.pr.loc[lat,lon] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3e4a4b-ea90-4a66-99da-70cc068050a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_domain = ds.where(mask).to_dataframe().dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76d1a9c-52b1-4d00-97a4-e7f0502002af",
   "metadata": {},
   "source": [
    "Cool, df_domain only has data from our spatial domain of interest. Now group by day (\"time\") and aggregate (take the mean of) the precipitation (\"pr\") for each day.\n",
    "\n",
    "Also note precip comes in kilograms per square meter per second. To get per day, we need 3600 seconds per hour and 24 hours per day. 3600*24 is 86400. But, then there's the issue of kilograms per square meter. With typical density of water, kilograms per square meter is the same as millimeters of precip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dcc3d6e-7236-4bc5-9f28-6d012fe11a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "areal_agg = df_domain.groupby('time').mean().reset_index()\n",
    "areal_agg['prmm'] = areal_agg['pr'] * 86400\n",
    "\n",
    "if parameters['save_daily_timeseries']:\n",
    "    areal_agg[['time','prmm']].to_csv(parameters['path_for_saving_daily'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dba047ca-8f37-4955-86d0-ed320fb686a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "areal_agg['year'] = areal_agg['time'].dt.year # add a year column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15414707-8850-4d0d-8f70-3473b27373ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yearly max df\n",
    "ydf = areal_agg.groupby('year').max('prmm').reset_index()[['year','prmm']]\n",
    "\n",
    "if parameters['save_annual_max_timeseries']:\n",
    "    ydf.to_csv(parameters['path_for_saving_annual_max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236ea687-b620-407a-a5ce-21c35511ba63",
   "metadata": {},
   "source": [
    "Fit GEV distributions and get levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c48175ac-214f-4251-98d6-243d7327d2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return levels for Boston, climate during 2031-2050, covering the watersheds where the subway is, in millimeters):\n",
      "1/100 year level: 85.81062169587014\n",
      "1/25 year level: 80.84303770162066\n"
     ]
    }
   ],
   "source": [
    "data = ydf.prmm[ydf.year.between(2031, 2050)]\n",
    "\n",
    "shape, loc, scale = gev.fit(data)\n",
    "\n",
    "print('Return levels for Boston, climate during 2031-2050, covering the watersheds where the subway is, in millimeters):')\n",
    "print('1/100 year level:', gev.isf(1/100,shape,loc,scale))\n",
    "print('1/25 year level:', gev.isf(1/25,shape,loc,scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c97295dc-22a7-400e-a83e-24be51f059af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return levels for Boston, climate during 2081-2100, covering the watersheds where the subway is, in millimeters):\n",
      "1/100 year level: 135.2133895888229\n",
      "1/25 year level: 115.53216758246845\n"
     ]
    }
   ],
   "source": [
    "data = ydf.prmm[ydf.year.between(2081, 2100)]\n",
    "\n",
    "shape, loc, scale = gev.fit(data)\n",
    "\n",
    "print('Return levels for Boston, climate during 2081-2100, covering the watersheds where the subway is, in millimeters):')\n",
    "print('1/100 year level:', gev.isf(1/100,shape,loc,scale))\n",
    "print('1/25 year level:', gev.isf(1/25,shape,loc,scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a4b635-545c-40aa-840e-235057a048f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
